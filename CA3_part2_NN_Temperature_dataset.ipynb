{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamadoz79/Neural_networks_CA3/blob/main/CA3_part2_NN_Temperature_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj2TMfNNfOIV"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import *\n",
        "from scipy.linalg import norm, pinv\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.cluster import MiniBatchKMeans as kmeans\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import random\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ1XxfV0WAAV",
        "outputId": "9d1fed55-e28a-4e44-bb26-a8940f24204c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZsgTHyOWaTA"
      },
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4wTINVdS9HS"
      },
      "outputs": [],
      "source": [
        "def normalize(df_min_max_scaled):\n",
        "    for column in df_min_max_scaled.columns:\n",
        "        df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n",
        "    return df_min_max_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAc-Ta8-g2G7",
        "outputId": "65ffffa4-7d86-45a2-e0bc-950673feba83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d8db9858f8fc>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n",
            "<ipython-input-3-d8db9858f8fc>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n"
          ]
        }
      ],
      "source": [
        "data_sets = {}\n",
        "for i in os.listdir('/content/drive/MyDrive/Time-series/'):\n",
        "    name = i.split('.')[0]\n",
        "    data_sets.update({name : pd.read_excel(f\"/content/drive/MyDrive/Time-series/{i}\", header=None)})\n",
        "    data_sets[name] = {\"target\": np.array(normalize(data_sets[name].iloc[:,-1:])), \"data\": np.array(normalize(data_sets[name].iloc[:,:-1]))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOn8Cfc_W1_n"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_sets['Temperature Dataset']['data'], data_sets['Temperature Dataset']['target'], test_size=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972h4AZHWbqx"
      },
      "source": [
        "GMDH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DXmbunHV7Mi"
      },
      "outputs": [],
      "source": [
        "class GMDH:\n",
        "    def __init__(self):\n",
        "        self.weights = np.array([random.random() for i in range(6)])\n",
        "        self.etha = 0.01\n",
        "        self.outputs = []\n",
        "        self.test_output = []\n",
        "        self.error_test = []\n",
        "        self.error_train = []\n",
        "        self.local_error_test = []\n",
        "        self.local_error_train = []\n",
        "\n",
        "    def feed_forward(self, X, target, test_flag):\n",
        "        self.x1, self.x2 = X\n",
        "        self.target = target\n",
        "        self.output = self.dot_product()\n",
        "        self.error = self.calc_error()\n",
        "        if not test_flag:\n",
        "            self.outputs.append(self.output)\n",
        "            self.local_error_train.append(self.error)\n",
        "        else:\n",
        "            self.test_output.append(self.output)\n",
        "            self.local_error_test.append(self.error)\n",
        "\n",
        "    def make_error_list(self, arg):\n",
        "        if arg == 'test':\n",
        "            self.error_test.append(self.local_error_test)\n",
        "            self.local_error_test = []\n",
        "        elif arg == 'train':\n",
        "            self.error_train.append(self.local_error_train)\n",
        "            self.local_error_train = []\n",
        "\n",
        "    def back_propag(self):\n",
        "        self.weights -= (np.array([1, self.x1, self.x2, self.x1**2, self.x1*self.x2, self.x2**2]) * self.error * -1 * self.etha)\n",
        "\n",
        "    def dot_product(self):\n",
        "        return self.weights[0] + self.weights[1]*self.x1 + self.weights[2]*self.x2 + self.weights[3]*(self.x1**2) + self.weights[4]*(self.x1*self.x2) + self.weights[5]*(self.x2**2)\n",
        "\n",
        "    def calc_error(self):\n",
        "        return self.target - self.output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v81hD41UhbLb"
      },
      "outputs": [],
      "source": [
        "GMDH_neurons_layer_1 = [GMDH() for i in range(3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWIEZx2ig6UF"
      },
      "outputs": [],
      "source": [
        "def GMDH_training(Data, Target, Data_test, Target_test, epoch=200, GMDH_neurons=GMDH_neurons_layer_1):\n",
        "    for ep in range(epoch):\n",
        "        for neuron in GMDH_neurons:\n",
        "            neuron.outputs = []\n",
        "        #train part\n",
        "        for (data, target) in zip(Data, Target):\n",
        "            [i.feed_forward(j, target[0], False) for (i, j) in zip(GMDH_neurons, list(itertools.combinations(data, 2)))]\n",
        "            [i.back_propag() for i in GMDH_neurons]\n",
        "        for ne in GMDH_neurons:\n",
        "            ne.make_error_list('train')\n",
        "\n",
        "        for neuron in GMDH_neurons:\n",
        "            neuron.test_output = []\n",
        "\n",
        "        for (data, target) in zip(Data_test, Target_test):\n",
        "            [i.feed_forward(j, target[0], True) for (i, j) in zip(GMDH_neurons, list(itertools.combinations(data, 2)))]\n",
        "        for ne in GMDH_neurons:\n",
        "            ne.make_error_list('test')\n",
        "\n",
        "    for neuron in GMDH_neurons:\n",
        "        neuron.outputs = np.array(neuron.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuIKtewPKM58"
      },
      "outputs": [],
      "source": [
        "GMDH_training(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GMDH_neurons_layer_2 = [GMDH() for i in range(3)]"
      ],
      "metadata": {
        "id": "la0B0WdJlN3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CEIAbgP9kT-"
      },
      "outputs": [],
      "source": [
        "GMDH_neurons_layer_2_x_train = np.array(list(zip(*[i.outputs for i in GMDH_neurons_layer_1])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GMDH_neurons_layer_2_x_test = np.array(list(zip(*[i.test_output for i in GMDH_neurons_layer_1])))"
      ],
      "metadata": {
        "id": "Oo_VI2GKFy2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GMDH_training(GMDH_neurons_layer_2_x_train, y_train, GMDH_neurons_layer_2_x_test, y_test, GMDH_neurons=GMDH_neurons_layer_2)"
      ],
      "metadata": {
        "id": "cVreJ89flel5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_x_train = np.array(list(zip(*[i.outputs for i in GMDH_neurons_layer_2])))\n",
        "mlp_x_test = np.array(list(zip(*[i.test_output for i in GMDH_neurons_layer_2])))"
      ],
      "metadata": {
        "id": "Qe9GAxygwr8z"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HCTOJi1WdAp"
      },
      "source": [
        "MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self):\n",
        "        self.weights = np.array([random.random() for i in range(3)])\n",
        "        self.etha = 0.01\n",
        "        self.outputs = []\n",
        "        self.test_output = []\n",
        "        self.error_test = []\n",
        "        self.error_train = []\n",
        "        self.local_error_test = []\n",
        "        self.local_error_train = []\n",
        "\n",
        "    def feed_forward(self, X, test_flag):\n",
        "        self.x = X\n",
        "        self.net = sum(self.weight * self.x)\n",
        "        self.output = self.sigmoid(self.net)\n",
        "        if not test_flag:\n",
        "            self.outputs.append(self.output)\n",
        "            self.local_error_train.append(self.error)\n",
        "        else:\n",
        "            self.test_output.append(self.output)\n",
        "            self.local_error_test.append(self.error)\n",
        "\n",
        "    def make_error_list(self, arg):\n",
        "        if arg == 'test':\n",
        "            self.error_test.append(self.local_error_test)\n",
        "            self.local_error_test = []\n",
        "        elif arg == 'train':\n",
        "            self.error_train.append(self.local_error_train)\n",
        "            self.local_error_train = []\n",
        "\n",
        "    def back_propag(self, rgh_flag):\n",
        "        pass\n",
        "\n",
        "    def sigmoid(self, z, first_derivative=False):\n",
        "        if first_derivative:\n",
        "            return z*(1.0-z)\n",
        "        return 1.0/(1.0+np.exp(-z))\n",
        ""
      ],
      "metadata": {
        "id": "BpfS3GmCwBB-"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_training(Data, Target, Data_test, Target_test, epoch=200, mlp_neurons=mlp_neurons):\n",
        "    for ep in range(epoch):\n",
        "        for neuron in mlp_neurons:\n",
        "            neuron.outputs = []\n",
        "        #train part\n",
        "        for data in Data:\n",
        "            [i.feed_forward(data, False) for i in mlp_neurons]\n",
        "            #[i.back_propag() for i in mlp_neurons]\n",
        "        for ne in mlp_neurons:\n",
        "            ne.make_error_list('train')\n",
        "\n",
        "        for neuron in mlp_neurons:\n",
        "            neuron.test_output = []\n",
        "        '''\n",
        "        for (data, target) in zip(Data_test, Target_test):\n",
        "            [i.feed_forward(j, target[0], True) for (i, j) in zip(mlp_neurons, list(itertools.combinations(data, 2)))]\n",
        "        for ne in mlp_neurons:\n",
        "            ne.make_error_list('test')\n",
        "        '''\n",
        "    for neuron in mlp_neurons:\n",
        "        neuron.outputs = np.array(neuron.outputs)"
      ],
      "metadata": {
        "id": "-gqD6noo4Ukf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Rough:\n",
        "    def __init__(self, inp_size):\n",
        "        self.weightsL = np.array([random.random() for i in range(inp_size)])\n",
        "        self.weightsU = np.array([random.random() for i in range(inp_size)])\n",
        "        self.alpha = random.rand()\n",
        "        self.beta = random.rand()\n",
        "        self.etha = 0.01\n",
        "        self.outputsL = []\n",
        "        self.outputsU = []\n",
        "\n",
        "        self.test_output = []\n",
        "        self.error_test = []\n",
        "        self.error_train = []\n",
        "        self.local_error_test = []\n",
        "        self.local_error_train = []\n",
        "\n",
        "    def feed_forward(self, X, target, test_flag):\n",
        "        self.x = X\n",
        "        self.target = target\n",
        "        self.netU = sum(self.weightU * self.x)\n",
        "        self.netL = sum(self.weightL * self.x)\n",
        "        self.outputU = max(self.netU, self.netL)\n",
        "        self.outputL = min(self.netU, self.netL)\n",
        "        self.flag = self.netU > self.netL\n",
        "        self.output = self.alpha * self.outputU + self.beta * self.outputL\n",
        "        self.error = self.calc_error()\n",
        "        if not test_flag:\n",
        "            self.outputs.append(self.output)\n",
        "            self.local_error_train.append(self.error)\n",
        "\n",
        "        else:\n",
        "            self.test_output.append(self.output)\n",
        "            self.local_error_test.append(self.error)\n",
        "\n",
        "    def make_error_list(self, arg):\n",
        "        if arg == 'test':\n",
        "            self.error_test.append(self.local_error_test)\n",
        "            self.local_error_test = []\n",
        "        elif arg == 'train':\n",
        "            self.error_train.append(self.local_error_train)\n",
        "            self.local_error_train = []\n",
        "\n",
        "    def back_propag(self, rgh_flag):\n",
        "        self.alpha += self.etha * self.error * self.outputU\n",
        "        self.beta += self.etha * self.error * self.outputL\n",
        "        self.weightsU += self.etha * self.error * self.x * (self.flag * self.alpha + (1 - self.flag) * self.beta)\n",
        "        self.weightsL += self.etha * self.error * self.x * ((1 - self.flag) * self.alpha + self.flag * self.beta)\n",
        "\n",
        "\n",
        "    def linear(self, x, derivative=False):\n",
        "        if derivative:\n",
        "            return 1\n",
        "        return x\n",
        "\n",
        "    def calc_error(self):\n",
        "        return self.target - self.output"
      ],
      "metadata": {
        "id": "72ryON8b0bwx"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Rough_training(Data, Target, Data_test, Target_test, rough_neuron=rough_neuron):\n",
        "    for neuron in rough_neuron:\n",
        "        neuron.outputs = []\n",
        "    #train part\n",
        "    for data in Data:\n",
        "        [i.feed_forward(data, False) for i in rough_neuron]\n",
        "        #[i.back_propag() for i in rough_neuron]\n",
        "    for ne in rough_neuron:\n",
        "        ne.make_error_list('train')\n",
        "\n",
        "    for neuron in rough_neuron:\n",
        "        neuron.test_output = []\n",
        "    '''\n",
        "    for (data, target) in zip(Data_test, Target_test):\n",
        "        [i.feed_forward(j, target[0], True) for (i, j) in zip(rough_neuron, list(itertools.combinations(data, 2)))]\n",
        "    for ne in rough_neuron:\n",
        "        ne.make_error_list('test')\n",
        "    '''\n",
        "    for neuron in rough_neuron:\n",
        "        neuron.outputs = np.array(neuron.outputs)"
      ],
      "metadata": {
        "id": "hZeEfz6M5_Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_neurons = [MLP() for i in range(5)]"
      ],
      "metadata": {
        "id": "OwV8aWZs3O-E"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rough_neuron = Rough(inp_size=5)"
      ],
      "metadata": {
        "id": "dptZ0NpO3UBC"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in mlp_x_train:\n",
        "    mlp.feed_forward(i)"
      ],
      "metadata": {
        "id": "hkv9J8i735XI"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgUI8kNn4FKa",
        "outputId": "232cf481-5ecc-441f-c636-9621658fbfd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nmdcw30u4IwD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}